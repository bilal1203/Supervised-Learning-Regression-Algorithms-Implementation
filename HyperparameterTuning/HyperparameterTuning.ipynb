{"cells":[{"cell_type":"code","execution_count":877,"metadata":{},"outputs":[],"source":["import time\n","\n","import pandas as pd\n","import numpy as np\n","\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.model_selection import KFold, GridSearchCV, RandomizedSearchCV, cross_val_score\n","from sklearn.metrics import make_scorer, mean_squared_error\n","\n","from xgboost import XGBRegressor\n","from lightgbm import LGBMRegressor\n","from catboost import CatBoostRegressor\n","from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor, RandomForestRegressor, BaggingRegressor, ExtraTreesRegressor\n","from sklearn.linear_model import ElasticNet, HuberRegressor, Lasso, LinearRegression, OrthogonalMatchingPursuit, Ridge, RANSACRegressor, TheilSenRegressor\n","from sklearn.gaussian_process import GaussianProcessRegressor\n","from sklearn.kernel_ridge import KernelRidge\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.svm import SVR\n","from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n","from sklearn.neural_network import MLPRegressor\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.cross_decomposition import PLSRegression\n","\n","from warnings import filterwarnings\n","filterwarnings('ignore')"]},{"cell_type":"code","execution_count":878,"metadata":{},"outputs":[],"source":["df_train_copy = pd.read_csv('../Datasets/preprocessed_datasets/final_selected_features_data_copy.csv')\n","df_test = pd.read_csv('../Datasets/preprocessed_datasets/final_selected_features_df_test.csv')"]},{"cell_type":"code","execution_count":879,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', '1stFlrSF', 'GarageFinish', 'Fireplaces', 'OpenPorchSF', 'LotArea', 'CentralAir_Y', 'YearRemodAdd_Age', 'YearBuilt_Age']\n"]}],"source":["features = [col for col in df_train_copy.columns if col != \"SalePrice\"]\n","print(features)"]},{"cell_type":"code","execution_count":880,"metadata":{},"outputs":[],"source":["# Define hyperparameter grids for each model\n","param_grids = {\n","    # \"GradientBoostingRegressor\": {\n","    #     'n_estimators': [50, 1000, 3000, 5000],\n","    #     'learning_rate': [0.05, 0.1, 0.15],\n","    #     'max_depth': [3, 5, 8],\n","    #     'loss': ['huber', 'quantile'],\n","    #     'min_samples_split': [5, 10, 15],\n","    #     'min_samples_leaf': [5, 10, 15],\n","    #     'max_features': [None, 'sqrt', 'log2']\n","    # },\n","    # \"GradientBoostingRegressor\": {\n","    #     'learning_rate': [0.05], \n","    #     'loss': ['huber'], \n","    #     'max_depth': [4], \n","    #     'max_features': ['sqrt'], \n","    #     'min_samples_leaf': [15], \n","    #     'min_samples_split': [10], \n","    #     'n_estimators': [280]\n","    # },\n","    # \"AdaBoostRegressor\": {\n","    #     'n_estimators': [50, 150, 1000, 3000, 5000],\n","    #     'learning_rate': [0.05, 0.1, 0.15],\n","    #     'loss': ['linear', 'square', 'exponential'],\n","    # },\n","    # \"AdaBoostRegressor\": {\n","    #     'n_estimators': [150],\n","    #     'learning_rate': [0.05],\n","    #     'loss': ['exponential'],\n","    # },\n","    # \"RandomForestRegressor\": {\n","    #     'n_estimators': [50, 1000, 3000, 5000],\n","    #     'max_depth': [3, 5, 8],\n","    #     'min_samples_split': [5, 10, 15],\n","    #     'min_samples_leaf': [5, 10, 15],\n","    #     'bootstrap': [True, False]\n","    # },\n","    # \"RandomForestRegressor\": {\n","    #     'n_estimators': [450],\n","    #     'max_depth': [8],\n","    #     'min_samples_split': [5],\n","    #     'min_samples_leaf': [5],\n","    #     'bootstrap': [True]\n","    # },\n","    # \"BaggingRegressor\": {\n","    #     'n_estimators': [50, 100, 150, 200],\n","    #     'max_samples': [0.5, 0.7, 0.9],\n","    #     'max_features': [0.5, 0.7, 0.9],\n","    #     'bootstrap': [True, False],\n","    #     'bootstrap_features': [True, False]\n","    # },\n","    # \"BaggingRegressor\": {\n","    #     'n_estimators': [300],\n","    #     'max_samples': [0.7],\n","    #     'max_features': [0.7],\n","    #     'bootstrap': [True],\n","    #     'bootstrap_features': [False]\n","    # },\n","    # \"XGBRegressor\": {\n","    #     'n_estimators': [150, 200, 250, 300],\n","    #     'learning_rate': [0.03, 0.05],\n","    #     'max_depth': [3, 5],\n","    #     'colsample_bytree': [0.4, 0.45, 0.5],\n","    #     'gamma': [0.05, 0.1, 0.15],\n","    #     'min_child_weight': [1, 2, 3],\n","    #     'reg_alpha': [0.5, 1, 1.5],\n","    #     'reg_lambda': [0.5, 1, 1.5],\n","    #     'subsample': [0.5, 0.75, 0.9],\n","    # },\n","    # \"XGBRegressor\": {\n","    #     'colsample_bytree': 0.5,\n","    #     'gamma': 0.05,\n","    #     'learning_rate': 0.03,\n","    #     'max_depth': 5,\n","    #     'min_child_weight': 2,\n","    #     'n_estimators': 300,\n","    #     'reg_alpha': 0.5,\n","    #     'reg_lambda': 1,\n","    #     'subsample': 0.5\n","    # },\n","    # \"LGBMRegressor\": {\n","    #     'n_estimators': [300, 500, 800, 1000],\n","    #     'learning_rate': [0.03, 0.05],\n","    #     'max_depth': [3, 5, -1],  # -1 means no limit\n","    #     'num_leaves': [3, 5, 8],  # Number of leaves in full trees\n","    #     'min_child_samples': [5, 11, 20, 50],  # Minimum number of samples per leaf\n","    #     'subsample': [0.6, 0.8, 1.0],  # Fraction of samples for each tree\n","    #     'colsample_bytree': [0.6, 0.8, 1.0],  # Fraction of features for each tree\n","    #     'reg_alpha': [0, 0.1, 1, 10],  # L1 regularization term\n","    #     'reg_lambda': [0, 0.1, 1, 10],  # L2 regularization term\n","    #     'min_split_gain': [0, 0.1, 0.5],  # Minimum gain to make a split\n","    #     'verbose': [0]  # Suppress output\n","    # }\n","    # \"LGBMRegressor\": {\n","    #     'n_estimators': [730],\n","    #     'learning_rate': [0.03],\n","    #     'max_depth': [3],\n","    #     'num_leaves': [5],\n","    #     'min_child_samples': [11],\n","    #     'colsample_bytree': [0.6],\n","    #     'reg_alpha': [1],\n","    #     'verbose': [0]\n","    # },\n","    # \"CatBoostRegressor\": {\n","    #     'iterations': [50, 100, 150, 200, 300, 400],\n","    #     'learning_rate': [0.01, 0.03, 0.05, 0.1, 0.15, 0.2],\n","    #     'depth': [3, 5, 8],\n","    #     'verbose': [False]\n","    # },\n","    # \"CatBoostRegressor\": {\n","    #     'iterations': [500],\n","    #     'learning_rate': [0.03],\n","    #     'depth': [5],\n","    #     'verbose': [False]\n","    # },\n","    # \"ElasticNet\": {\n","    #     'alpha': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1],\n","    #     'l1_ratio': [0.1, 0.5, 0.9]\n","    # },\n","    # \"ElasticNet\": {\n","    #     'alpha': [0.002],\n","    #     'l1_ratio': [0.9]\n","    # },\n","    \"HuberRegressor\": {\n","        'alpha': [0.01, 0.1, 1, 10, 100]\n","    },\n","    # \"Lasso\": {\n","    #     'alpha': [0.01, 0.1, 1, 10, 100]\n","    # },\n","    # \"LinearRegression\": {\n","    #     # No hyperparameters to tune for linear regression\n","    # },\n","    # \"OrthogonalMatchingPursuit\": {\n","    #     'n_nonzero_coefs': [None, 5, 10, 20, 30]\n","    # },\n","    # \"Ridge\": {\n","    #     'alpha': [0.01, 0.1, 1, 10, 100]\n","    # },\n","    # \"RANSACRegressor\": {\n","    #     'min_samples': [0.1, 0.5, 0.9],\n","    #     'residual_threshold': [1.0, 2.0, 3.0]\n","    # },\n","    # \"TheilSenRegressor\": {\n","    #     'max_subpopulation': [1e3, 1e4, 1e5]\n","    # },\n","    # \"GaussianProcessRegressor\": {\n","    #     'alpha': [1e-2, 1e-3, 1e-10]\n","    # },\n","    # \"KernelRidge\": {\n","    #     'alpha': [0.01, 0.1, 1, 10, 100],\n","    #     'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n","    # },\n","    # \"KNeighborsRegressor\": {\n","    #     'n_neighbors': [3, 5, 7, 9, 11],\n","    #     'weights': ['uniform', 'distance']\n","    # },\n","    # \"SVR\": {\n","    #     'C': [0.1, 1, 10, 100],\n","    #     'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n","    # },\n","    # \"DecisionTreeRegressor\": {\n","    #     'max_depth': [3, 5, 8, None],\n","    #     'min_samples_split': [2, 5, 10],\n","    #     'min_samples_leaf': [1, 2, 4]\n","    # },\n","    # \"ExtraTreeRegressor\": {\n","    #     'max_depth': [3, 5, 8, None],\n","    #     'min_samples_split': [2, 5, 10],\n","    #     'min_samples_leaf': [1, 2, 4]\n","    # },\n","    # \"MLPRegressor\": {\n","    #     'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n","    #     'activation': ['relu', 'tanh'],\n","    #     'solver': ['adam', 'sgd'],\n","    #     'learning_rate': ['constant', 'invscaling', 'adaptive']\n","    # },\n","    # \"make_pipeline(PolynomialFeatures(degree=2), LinearRegression)\": {\n","    #     # No hyperparameters to tune for this pipeline\n","    # },\n","    # \"PLSRegression\": {\n","    #     'n_components': [2, 4, 6, 8, 10]\n","    # }\n","}"]},{"cell_type":"code","execution_count":881,"metadata":{},"outputs":[],"source":["# Splitting data for cross-validation using KFold splitting\n","kf = KFold(n_splits=10, shuffle=True, random_state=619)"]},{"cell_type":"code","execution_count":882,"metadata":{},"outputs":[],"source":["# Create a table to store results of GridSearchCV\n","results_columns = ['Model', 'Best Params', 'Best Score', 'Best Model', 'Refit Time']\n","results_df = pd.DataFrame(columns=results_columns)"]},{"cell_type":"code","execution_count":883,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting model: ElasticNet...\n","Fitting 10 folds for each of 1 candidates, totalling 10 fits\n","Total time taken by Hyperparameter tuning is 0.00 minutes.\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Best Params</th>\n","      <th>Best Score</th>\n","      <th>Best Model</th>\n","      <th>Refit Time</th>\n","      <th>Total Model Grid Search Tuning Time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ElasticNet</td>\n","      <td>{'alpha': 0.002, 'l1_ratio': 0.9}</td>\n","      <td>0.35462</td>\n","      <td>ElasticNet(alpha=0.002, l1_ratio=0.9, random_s...</td>\n","      <td>0.003995</td>\n","      <td>0.045829</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Model                        Best Params Best Score  \\\n","0  ElasticNet  {'alpha': 0.002, 'l1_ratio': 0.9}    0.35462   \n","\n","                                          Best Model Refit Time  \\\n","0  ElasticNet(alpha=0.002, l1_ratio=0.9, random_s...   0.003995   \n","\n","   Total Model Grid Search Tuning Time  \n","0                             0.045829  "]},"metadata":{},"output_type":"display_data"}],"source":["# Perform hyperparameter tuning for each model and store results row-wise\n","total_start_time = time.time()\n","\n","index = 0\n","\n","for model_name, param_grid in param_grids.items():\n","\n","    print(f\"Fitting model: {model_name}...\")\n","\n","    # Instantiate model from string name\n","    if model_name == \"make_pipeline(PolynomialFeatures(degree=2), LinearRegression)\":\n","        model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n","    else:\n","        model = eval(model_name)(random_state=619)\n","\n","    start_time = time.time()\n","    search = GridSearchCV(model, param_grid, scoring=make_scorer(mean_squared_error, squared=False), cv=kf, verbose=1, n_jobs=-1)\n","    search.fit(df_train_copy[features], df_train_copy[\"SalePrice\"])\n","    end_time = time.time()\n","    \n","    # Store results\n","    results_df.loc[index, 'Model'] = model.__class__.__name__\n","    results_df.loc[index, 'Best Params'] = str(search.best_params_)\n","    results_df.loc[index, 'Best Model'] = str(search.best_estimator_)\n","    results_df.loc[index, 'Best Score'] = search.best_score_\n","    results_df.loc[index, 'Refit Time'] = search.refit_time_\n","    results_df.loc[index, 'Total Model Grid Search Tuning Time'] = end_time - start_time\n","\n","    index += 1\n","\n","total_end_time = time.time()\n","\n","total_run_time = total_end_time - total_start_time\n","print('Total time taken by Hyperparameter tuning is {:.2f} minutes.'.format(total_run_time / 60))\n","\n","# Print the model results in ascending order to get the best performing model\n","results_df.sort_values('Best Score', ascending=True, inplace=True)\n","display(results_df)"]},{"cell_type":"code","execution_count":884,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>params</th>\n","      <th>mean_test_score</th>\n","      <th>std_test_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>{'alpha': 0.002, 'l1_ratio': 0.9}</td>\n","      <td>0.35462</td>\n","      <td>0.035176</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                              params  mean_test_score  std_test_score\n","0  {'alpha': 0.002, 'l1_ratio': 0.9}          0.35462        0.035176"]},"metadata":{},"output_type":"display_data"}],"source":["pd.set_option('display.max_colwidth', None)\n","\n","results = search.cv_results_\n","results_df = pd.DataFrame({\n","    'params': results['params'],\n","    'mean_test_score': results['mean_test_score'],\n","    'std_test_score': results['std_test_score']\n","})\n","display(results_df.sort_values(\"mean_test_score\"))\n","\n","pd.reset_option('display.max_colwidth')"]},{"cell_type":"code","execution_count":885,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Could not interpret value `Best Score` for `x`. An entry with this name does not appear in `data`.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[885], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Plotting the results\u001b[39;00m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m sns\u001b[38;5;241m.\u001b[39mbarplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest Score\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mresults_df, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#097969\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMACHINE LEARNING ALGORITHM BEST RMSE SCORE After Hyperparameter Tuning: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest RMSE Score\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[1;32mc:\\Users\\bilal\\miniconda3\\envs\\ml_env\\Lib\\site-packages\\seaborn\\categorical.py:2341\u001b[0m, in \u001b[0;36mbarplot\u001b[1;34m(data, x, y, hue, order, hue_order, estimator, errorbar, n_boot, seed, units, weights, orient, color, palette, saturation, fill, hue_norm, width, dodge, gap, log_scale, native_scale, formatter, legend, capsize, err_kws, ci, errcolor, errwidth, ax, **kwargs)\u001b[0m\n\u001b[0;32m   2338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mlen\u001b[39m:\n\u001b[0;32m   2339\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2341\u001b[0m p \u001b[38;5;241m=\u001b[39m _CategoricalAggPlotter(\n\u001b[0;32m   2342\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m   2343\u001b[0m     variables\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(x\u001b[38;5;241m=\u001b[39mx, y\u001b[38;5;241m=\u001b[39my, hue\u001b[38;5;241m=\u001b[39mhue, units\u001b[38;5;241m=\u001b[39munits, weight\u001b[38;5;241m=\u001b[39mweights),\n\u001b[0;32m   2344\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   2345\u001b[0m     orient\u001b[38;5;241m=\u001b[39morient,\n\u001b[0;32m   2346\u001b[0m     color\u001b[38;5;241m=\u001b[39mcolor,\n\u001b[0;32m   2347\u001b[0m     legend\u001b[38;5;241m=\u001b[39mlegend,\n\u001b[0;32m   2348\u001b[0m )\n\u001b[0;32m   2350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2351\u001b[0m     ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mgca()\n","File \u001b[1;32mc:\\Users\\bilal\\miniconda3\\envs\\ml_env\\Lib\\site-packages\\seaborn\\categorical.py:67\u001b[0m, in \u001b[0;36m_CategoricalPlotter.__init__\u001b[1;34m(self, data, variables, order, orient, require_numeric, color, legend)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     58\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     legend\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     65\u001b[0m ):\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(data\u001b[38;5;241m=\u001b[39mdata, variables\u001b[38;5;241m=\u001b[39mvariables)\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# This method takes care of some bookkeeping that is necessary because the\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# original categorical plots (prior to the 2021 refactor) had some rules that\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# don't fit exactly into VectorPlotter logic. It may be wise to have a second\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;66;03m# default VectorPlotter rules. If we do decide to make orient part of the\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;66;03m# _base variable assignment, we'll want to figure out how to express that.\u001b[39;00m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwide\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n","File \u001b[1;32mc:\\Users\\bilal\\miniconda3\\envs\\ml_env\\Lib\\site-packages\\seaborn\\_base.py:634\u001b[0m, in \u001b[0;36mVectorPlotter.__init__\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;66;03m# var_ordered is relevant only for categorical axis variables, and may\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;66;03m# be better handled by an internal axis information object that tracks\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# such information and is set up by the scale_* methods. The analogous\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# information for numeric axes would be information about log scales.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_ordered \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}  \u001b[38;5;66;03m# alt., used DefaultDict\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massign_variables(data, variables)\n\u001b[0;32m    636\u001b[0m \u001b[38;5;66;03m# TODO Lots of tests assume that these are called to initialize the\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;66;03m# mappings to default values on class initialization. I'd prefer to\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;66;03m# move away from that and only have a mapping when explicitly called.\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyle\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n","File \u001b[1;32mc:\\Users\\bilal\\miniconda3\\envs\\ml_env\\Lib\\site-packages\\seaborn\\_base.py:679\u001b[0m, in \u001b[0;36mVectorPlotter.assign_variables\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;66;03m# When dealing with long-form input, use the newer PlotData\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;66;03m# object (internal but introduced for the objects interface)\u001b[39;00m\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;66;03m# to centralize / standardize data consumption logic.\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlong\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 679\u001b[0m     plot_data \u001b[38;5;241m=\u001b[39m PlotData(data, variables)\n\u001b[0;32m    680\u001b[0m     frame \u001b[38;5;241m=\u001b[39m plot_data\u001b[38;5;241m.\u001b[39mframe\n\u001b[0;32m    681\u001b[0m     names \u001b[38;5;241m=\u001b[39m plot_data\u001b[38;5;241m.\u001b[39mnames\n","File \u001b[1;32mc:\\Users\\bilal\\miniconda3\\envs\\ml_env\\Lib\\site-packages\\seaborn\\_core\\data.py:58\u001b[0m, in \u001b[0;36mPlotData.__init__\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     53\u001b[0m     data: DataSource,\n\u001b[0;32m     54\u001b[0m     variables: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, VariableSpec],\n\u001b[0;32m     55\u001b[0m ):\n\u001b[0;32m     57\u001b[0m     data \u001b[38;5;241m=\u001b[39m handle_data_source(data)\n\u001b[1;32m---> 58\u001b[0m     frame, names, ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_variables(data, variables)\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe \u001b[38;5;241m=\u001b[39m frame\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;241m=\u001b[39m names\n","File \u001b[1;32mc:\\Users\\bilal\\miniconda3\\envs\\ml_env\\Lib\\site-packages\\seaborn\\_core\\data.py:232\u001b[0m, in \u001b[0;36mPlotData._assign_variables\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    231\u001b[0m         err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn entry with this name does not appear in `data`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m \n\u001b[0;32m    236\u001b[0m     \u001b[38;5;66;03m# Otherwise, assume the value somehow represents data\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \n\u001b[0;32m    238\u001b[0m     \u001b[38;5;66;03m# Ignore empty data structures\u001b[39;00m\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, Sized) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(val) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","\u001b[1;31mValueError\u001b[0m: Could not interpret value `Best Score` for `x`. An entry with this name does not appear in `data`."]},{"data":{"text/plain":["<Figure size 1200x800 with 0 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Plotting the results\n","plt.figure(figsize=(12, 8))\n","sns.barplot(x='Best Score', y='Model', data=results_df, color=\"#097969\")\n","\n","plt.title('MACHINE LEARNING ALGORITHM BEST RMSE SCORE After Hyperparameter Tuning: \\n')\n","plt.xlabel('Best RMSE Score')\n","plt.ylabel('Algorithm')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"ml_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":2}
